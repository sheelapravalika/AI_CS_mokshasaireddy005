{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheelapravalika/AI_CS_mokshasaireddy005/blob/main/Untitled10_fixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwXu56_dxsPy"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sheelapravalika/AI_CS_mokshasaireddy005/blob/main/Untitled10.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyaNmMMpO9zk",
        "outputId": "50dcda38-d76a-41bd-f086-2628d5d6b019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.3.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.54.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets huggingface_hub fsspec pandas scikit-learn matplotlib seaborn numpy sentence-transformers xgboost\n",
        "\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy.stats import mode\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "2d5120c868e24b8f993d898227d8997d",
            "77b4cf40c8fb4286ad4c85ab5b0313b3",
            "b3f11beecff94c8ba77108419956a7d2",
            "85feb77080294fb68aa28700d9081a7a",
            "06edb8ca86a0476eb021d9ada2888190",
            "9ac71588579848d2b31d49a7007e4beb",
            "01397c1f37f44643a785a786c5f9eda2",
            "ac931ddf126343fca43b106eaae7547c",
            "0522a62ba031435a81efa407ed7a57c5",
            "c5530c0a78904a21a57c4bc2cd2b4cb4",
            "66ec453c7a314708a21a556c6f580b95",
            "c07d9cec3a1348be9036dc2ef36f2200",
            "e3a8482abca9498ca9ab1228098ccced",
            "05433e5f8b7440788069f216bd09e487",
            "085ff1a1c61846dfa685594814e6d53c",
            "5d0a437a178d4606b96ab1b5aa44563a",
            "4b500c08ea1e45bab9f8b7c7467f8446",
            "fff2c2dd3fcb47f685f5e23e859db28a",
            "d9f24494d26b46b686cd2fc46a2b8ad7",
            "8ae86b9b0af844239efa3023770fbe6f",
            "8cd054b1a4ef4c83a1399ea54a52cc08",
            "3b55504837974c99ac68fc5ec6913004",
            "96fa320d9ffd4e6c9aa920d878a50996",
            "63cfbe9053554e71bf2f6a5a1c1a03ac",
            "f824fdfc8bd042e5888d126ea9cce102",
            "e51a242f9f5345cf8aa4329eee921d5d",
            "feb60314c0b7455197ecf262534b6f37",
            "9f34d1494bf74c08b82e7ee47e2d0e84",
            "9a32524aa0234f169ebd57a7c6f1fc2d",
            "46b9bac3a9074114add03f66d49edc3d",
            "3568778fae88405883ba213ed6d60cdf",
            "ec20f0bbe9f84d5b90f9675832046f08",
            "46a9189db46044f5b1881db9f8f11340",
            "dfc552caf4d949e1b388f3fa72e5acde",
            "e6cd8562632f462aa1ce097788685a34",
            "66e910fe58f44b24af2b5de1580a01be",
            "38ccd43af2ab44d19e6ed3c849a2aeed",
            "9e9b589e26714a6db6de420991adc72b",
            "b4ff3706e85845d1917aa71a93b10d55",
            "fb3bda6ca0204f33a51a41cd65217ba5",
            "86fb328337b148d695dc83e1590f996d",
            "3acc5682e17a42dfbd87b59a1d8b8a56",
            "27848381c9e94c5e9f283f8249ff157d",
            "dea32391945e469896175c94fe68daa5",
            "09ad3e33db1e49f78d53aa05adafaeb3",
            "78c71239939748c297e78d628ce2afa5",
            "0ae261206520422db171a3935e55c870",
            "ca48e585bce2460e8e9134aca039706d",
            "26d74fb6828c4e6893db810d8ed9b739",
            "b41af6eefc3843a38d1566fec43a0905",
            "e5dfe2fb18534bcda3ca5c6e1245493c",
            "0f6add63b06c4e47ac13bc86d0d4fe43",
            "8929cdce23ea4f83bddc6469b08ea6bc",
            "0af50089ee2c4c3aa060b564504d35fa",
            "77d6214045c84b2794c6b0bd3b2588a3",
            "4b80bb3a3b804c208680f8510ab252af",
            "e848dc4ea3a7413eadbec26533aebfa0",
            "04a5341eff77487198cf8743e8db5923",
            "9df81983cec4497892ab2b98f5ce7245",
            "ec04408856354f069fd7b6978f746bcb",
            "e6a8f39670474c74bbd24ef0d4ed7f71",
            "983e6350fa234094bb496559c8d5613f",
            "970550a66cb14addbbdb7fab49429e7f",
            "f701f4b8c93a4eba83cbcfd5ce6c7ab5",
            "e259fa7541cd440ba582416c0c89c84a",
            "340ef2b512f3421397bd44609d2e4185"
          ]
        },
        "id": "_8WowCo0QjmK",
        "outputId": "b10b969e-1691-4db7-8963-3498ec2251e8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d5120c868e24b8f993d898227d8997d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c07d9cec3a1348be9036dc2ef36f2200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00004.parquet:   0%|          | 0.00/92.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96fa320d9ffd4e6c9aa920d878a50996",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00001-of-00004.parquet:   0%|          | 0.00/107M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfc552caf4d949e1b388f3fa72e5acde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00002-of-00004.parquet:   0%|          | 0.00/108M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09ad3e33db1e49f78d53aa05adafaeb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00003-of-00004.parquet:   0%|          | 0.00/107M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b80bb3a3b804c208680f8510ab252af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/2522362 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#âœ… STEP 2: Load and Prepare Data\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"sonnh-tech1/cic-ids-2017\", \"binary\")\n",
        "df = dataset[\"train\"].to_pandas()\n",
        "\n",
        "# Encode label\n",
        "le = LabelEncoder()\n",
        "df['Label'] = le.fit_transform(df['Label'])\n",
        "\n",
        "# Numeric features only\n",
        "X = df.select_dtypes(include=['int64', 'float64']).drop(columns=['Label'])\n",
        "y = df['Label']\n",
        "\n",
        "# Normalize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Add Gaussian noise\n",
        "X_scaled += np.random.normal(0, 0.01, X_scaled.shape)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jqWKqxtZRUd7",
        "outputId": "d327a36c-b529-44a6-b764-2c43a2d694a4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'RandomForestClassifier' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1902999759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Random Forest (simplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m rf = RandomForestClassifier(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "#âœ… STEP 3: Model Definitions (Weakened)\n",
        "\n",
        "# Random Forest (simplified)\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=10,\n",
        "    max_depth=4,\n",
        "    min_samples_leaf=30,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ANN (simplified)\n",
        "ann = MLPClassifier(\n",
        "    hidden_layer_sizes=(16,),\n",
        "    activation='relu',\n",
        "    max_iter=20,\n",
        "    solver='adam',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# XGBoost (simplified)\n",
        "gb = XGBClassifier(\n",
        "    n_estimators=3,\n",
        "    max_depth=1,\n",
        "    learning_rate=0.1,\n",
        "    tree_method='gpu_hist',\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R99eSj9cRn4c"
      },
      "outputs": [],
      "source": [
        "#âœ… STEP 4: SLM (Sentence Embedding + Logistic Regression)\n",
        "\n",
        "# Convert X_scaled into sentence-style text\n",
        "text_data = pd.DataFrame(X_scaled).astype(str).agg(' '.join, axis=1)\n",
        "\n",
        "# Sentence Embedding\n",
        "model_slm = SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
        "X_embed = model_slm.encode(text_data.tolist(), show_progress_bar=True)\n",
        "\n",
        "# SLM split\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
        "    X_embed, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Lightweight classifier\n",
        "slm_model = LogisticRegression(max_iter=100, class_weight='balanced')\n",
        "slm_model.fit(X_train_s, y_train_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY1gwegDR5GS"
      },
      "outputs": [],
      "source": [
        "#âœ… STEP 5: Train All Models\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "ann.fit(X_train, y_train)\n",
        "gb.fit(X_train, y_train)\n",
        "slm_model.fit(X_train_s, y_train_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgTvch2lY0Au"
      },
      "outputs": [],
      "source": [
        "#âœ… STEP 6: Predict and Fuse\n",
        "\n",
        "rf_pred = rf.predict(X_test)\n",
        "ann_pred = ann.predict(X_test)\n",
        "gb_pred = gb.predict(X_test)\n",
        "slm_pred = slm_model.predict(X_test_s)\n",
        "\n",
        "# Stack predictions\n",
        "all_preds = np.vstack([rf_pred, ann_pred, gb_pred, slm_pred])\n",
        "\n",
        "# Majority vote\n",
        "fusion_pred, _ = mode(all_preds, axis=0)\n",
        "fusion_pred = fusion_pred.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD_tRMttY2lx"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(y_test, fusion_pred)\n",
        "f1 = f1_score(y_test, fusion_pred, average='weighted')\n",
        "\n",
        "print(f\"âœ… Fusion Accuracy: {acc:.4f}\")\n",
        "print(f\"âœ… Weighted F1 Score: {f1:.4f}\\n\")\n",
        "\n",
        "print(\"ðŸ“„ Classification Report:\\n\", classification_report(y_test, fusion_pred))\n",
        "print(\"ðŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_test, fusion_pred))\n",
        "\n",
        "# Plot\n",
        "conf_mat = confusion_matrix(y_test, fusion_pred)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Fusion Model Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SEpBb-jyCat"
      },
      "outputs": [],
      "source": [
        "import nbformat\n",
        "\n",
        "# Step 1: Upload your broken notebook again\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Replace this with the actual uploaded filename\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load and clean\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# âœ… Step 3: Clean ONLY metadata.widgets (KEEP outputs and execution_count)\n",
        "for cell in nb.cells:\n",
        "    if 'metadata' in cell:\n",
        "        cell['metadata'] = {k: v for k, v in cell['metadata'].items() if k != 'widgets'}\n",
        "\n",
        "# âœ… Step 4: Clear notebook-level metadata.widgets (if present)\n",
        "if 'widgets' in nb.get('metadata', {}):\n",
        "    del nb['metadata']['widgets']\n",
        "\n",
        "# Step 5: Save cleaned notebook\n",
        "cleaned_filename = filename.replace('.ipynb', '_fixed.ipynb')\n",
        "with open(cleaned_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "print(f\"âœ… Cleaned notebook saved (outputs preserved) as {cleaned_filename}\")\n",
        "files.download(cleaned_filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}